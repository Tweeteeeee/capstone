[2017-11-22T12:33:03,326][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T12:33:03,428][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T12:33:05,099][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T12:33:07,138][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T12:33:12,246][ERROR][logstash.outputs.elasticsearch] Unknown setting 'unit_id' for elasticsearch
[2017-11-22T12:33:12,247][ERROR][logstash.outputs.elasticsearch] Unknown setting 'name' for elasticsearch
[2017-11-22T12:33:12,247][ERROR][logstash.outputs.elasticsearch] Unknown setting 'hashtags' for elasticsearch
[2017-11-22T12:33:12,247][ERROR][logstash.outputs.elasticsearch] Unknown setting 'normalized_location' for elasticsearch
[2017-11-22T12:33:12,249][ERROR][logstash.outputs.elasticsearch] Unknown setting 'tweet_count' for elasticsearch
[2017-11-22T12:33:12,255][ERROR][logstash.outputs.elasticsearch] Unknown setting 'tweet_location' for elasticsearch
[2017-11-22T12:33:12,257][ERROR][logstash.outputs.elasticsearch] Unknown setting 'tweet_text' for elasticsearch
[2017-11-22T12:33:12,285][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Something is wrong with your configuration.", :backtrace=>["/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/config/mixin.rb:114:in `config_init'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/outputs/base.rb:63:in `initialize'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/output_delegator_strategies/shared.rb:3:in `initialize'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/output_delegator.rb:25:in `initialize'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:148:in `plugin'", "(eval):12:in `<eval>'", "org/jruby/RubyKernel.java:994:in `eval'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:82:in `initialize'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:215:in `initialize'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline_action/create.rb:35:in `execute'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:335:in `block in converge_state'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:332:in `block in converge_state'", "org/jruby/RubyArray.java:1734:in `each'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:319:in `converge_state'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:166:in `block in converge_state_and_update'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:141:in `with_pipelines'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:164:in `converge_state_and_update'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/agent.rb:90:in `execute'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/runner.rb:362:in `block in execute'", "/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/task.rb:24:in `block in initialize'"]}
[2017-11-22T12:54:00,489][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T12:54:00,505][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T12:54:01,673][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T12:54:03,220][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T12:54:05,753][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x52a58710@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T12:54:06,676][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T12:54:06,770][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T15:06:14,252][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T15:06:14,291][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T15:06:15,527][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T15:06:16,800][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T15:06:19,404][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x7a7e4eae@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T15:06:20,278][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T15:06:20,386][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T17:49:08,061][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T17:49:08,103][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T17:49:09,381][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T17:49:10,799][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T17:49:13,683][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x7a7e4eae@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T17:49:14,631][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T17:49:14,740][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T17:58:41,714][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T17:58:41,760][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T17:58:42,889][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T17:58:44,307][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T17:58:47,099][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x387e0240@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T17:58:47,891][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T17:58:47,977][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T18:00:41,988][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T18:00:42,039][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T18:00:43,566][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T18:00:45,149][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T18:00:50,544][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x7e91903d@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T18:00:51,594][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T18:00:51,960][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T18:22:01,042][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T18:22:01,071][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T18:22:02,224][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T18:22:03,536][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T18:22:06,185][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x4ec1d313@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T18:22:06,955][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T18:22:07,065][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T20:41:51,631][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T20:41:51,641][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T20:41:52,247][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T20:41:52,768][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T20:41:54,026][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x13858040@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T20:41:54,417][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T20:41:54,451][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T20:52:27,495][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T20:52:27,656][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2017-11-22T22:16:27,226][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T22:16:27,257][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T22:16:28,386][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T22:16:29,713][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T22:16:32,325][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x68a07710@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T22:16:33,061][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T22:16:33,158][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T22:17:01,914][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer
[2017-11-22T22:17:12,036][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLException: hostname: Temporary failure in name resolution"}
[2017-11-22T22:18:10,210][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLException: hostname: Temporary failure in name resolution"}
[2017-11-22T22:19:10,362][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLException: hostname: Temporary failure in name resolution"}
[2017-11-22T22:20:10,720][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLException: hostname: Temporary failure in name resolution"}
[2017-11-22T22:21:10,379][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::JavaSql::SQLException: hostname: Temporary failure in name resolution"}
[2017-11-22T22:21:41,245][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T22:21:41,653][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2017-11-22T22:24:24,741][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T22:24:24,767][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T22:24:26,016][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T22:24:27,572][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T22:24:30,522][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x48d4af70@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T22:24:31,474][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T22:24:31,604][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T22:25:02,820][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer
[2017-11-22T22:25:03,135][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:25:04,478][INFO ][com.datastax.driver.core.NettyUtil] Found Netty's native epoll transport in the classpath, using it
[2017-11-22T22:25:06,543][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:26:00,306][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:26:00,397][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:27:00,404][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:27:00,502][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:28:00,160][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:28:00,235][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:29:00,161][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:29:00,242][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:30:00,303][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:30:00,379][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:31:00,194][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:31:00,277][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:32:00,380][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:32:00,436][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:33:00,193][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:33:00,254][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:34:00,289][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:34:00,369][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:35:00,056][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:35:00,126][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:36:00,133][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:36:00,202][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:37:00,303][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:37:00,376][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:38:00,061][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:38:00,112][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:39:00,348][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:39:00,487][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:40:00,228][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:40:00,375][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:41:00,220][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:41:00,259][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:42:00,129][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:42:00,189][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:43:00,196][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:43:00,227][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:44:00,357][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:44:00,450][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:45:00,351][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:45:00,403][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:46:00,173][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:46:00,230][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:47:00,315][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:47:00,357][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:48:00,057][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:48:00,093][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:49:00,229][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:49:00,255][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:50:00,222][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:50:00,275][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:50:35,624][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T22:50:36,141][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2017-11-22T22:51:38,138][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T22:51:38,163][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T22:51:39,171][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T22:51:40,425][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T22:51:42,783][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x110997ed@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T22:51:43,496][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T22:51:43,620][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T22:52:01,869][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer
[2017-11-22T22:52:02,071][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T22:52:02,994][INFO ][com.datastax.driver.core.NettyUtil] Found Netty's native epoll transport in the classpath, using it
[2017-11-22T22:52:05,096][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T22:52:12,230][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T22:52:12,453][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2017-11-22T23:04:38,146][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T23:04:38,182][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T23:04:39,240][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T23:04:40,771][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T23:04:43,407][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x5d8f02d6@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T23:04:44,141][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T23:04:44,238][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T23:05:01,770][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer
[2017-11-22T23:05:02,012][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T23:05:02,902][INFO ][com.datastax.driver.core.NettyUtil] Found Netty's native epoll transport in the classpath, using it
[2017-11-22T23:05:04,493][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T23:05:08,395][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T23:05:08,722][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2017-11-22T23:39:35,951][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/fb_apache/configuration"}
[2017-11-22T23:39:35,998][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/modules/netflow/configuration"}
[2017-11-22T23:39:36,982][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2017-11-22T23:39:38,275][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2017-11-22T23:39:40,978][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>1, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>125, :thread=>"#<Thread:0x21f98b05@/home/zoe/Desktop/BigData/elasticsearch-6.0.0/logstash-6.0.0/logstash-core/lib/logstash/pipeline.rb:290 run>"}
[2017-11-22T23:39:41,699][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2017-11-22T23:39:41,768][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2017-11-22T23:40:01,758][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer
[2017-11-22T23:40:02,030][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.
[2017-11-22T23:40:03,286][INFO ][com.datastax.driver.core.NettyUtil] Found Netty's native epoll transport in the classpath, using it
[2017-11-22T23:40:05,105][ERROR][logstash.inputs.jdbc     ] Unable to connect to database. Tried 1 times {:error_message=>"Java::ComDatastaxDriverCoreExceptions::NoHostAvailableException: All host(s) tried for query failed (tried: localhost/127.0.0.1:9160 (com.datastax.driver.core.exceptions.TransportException: [localhost/127.0.0.1:9160] Channel has been closed))"}
[2017-11-22T23:40:07,595][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2017-11-22T23:40:07,795][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
